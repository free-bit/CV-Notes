{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering:\n",
    "\n",
    "[See for visualization](http://stanford.edu/class/ee103/visualizations/kmeans/kmeans.html)\n",
    "\n",
    "## Algorithm:\n",
    "\n",
    "1. Initialize cluster centers at $t=0$: $c_1, c_2, \\ldots c_k$\n",
    "2. Compute $\\delta^t$: Assign each data point to the closest cluster center.\n",
    "   - $\\displaystyle\\delta^t=\\underset{\\delta}{argmin}\\frac{1}{N}\\sum_j^N\\sum_i^K \\delta_{ij}^{t-1}(c_i^{t-1}-x_j)^2$\n",
    "   - where:\n",
    "     - $t$: iteration count, \n",
    "     - $j$: index of data point, $x_j$: $j$th data point, $N$: number of data points, \n",
    "     - $i$: index of cluster center, $c_i$: $i$th cluster center, $K$: number of clusters,\n",
    "     - $\\delta^t$: the set of assignment for each data point $x_j$ to cluster whose center $c_i$ at iteration $t$. \n",
    "3. Compute $c^t$: Update each cluster center as the mean of the points belonging to that cluster.\n",
    "    - $\\displaystyle c^t=\\underset{c}{argmin}\\frac{1}{N}\\sum_j^N\\sum_i^K \\delta_{ij}^{t}(c_i^{t-1}-x_j)^2$\n",
    "4. Update $t$: $t=t+1$ and repeat steps 2-3 until no change. \n",
    "\n",
    "## Facts:\n",
    "\n",
    "- Unsupervised learning method.\n",
    "- Converges to a local minimum solution.\n",
    "- Sensitive to outliers.\n",
    "- Needs to pick $K$ value:\n",
    "  - Requires experiments to find optimal number of clusters: elbow/knee finding.\n",
    "- All clusters need to have the same parameters.\n",
    "- Might be slow: $O(KNd)$ for $N$-many $d$-dimensional data points with $K$ clusters.\n",
    "- Provides a better fit for spherical data.\n",
    "- Clustering based on (r,g,b,x,y) values enforces more spatial coherence.\n",
    "\n",
    "## Python Implementation:\n",
    "```python\n",
    "def kmeans(feat_vecs, k, max_iter=10):\n",
    "    n, m = feat_vecs.shape\n",
    "    proceed = True\n",
    "    centers = None\n",
    "    while (proceed):\n",
    "        proceed = False\n",
    "        centers = np.random.uniform(size=(k, m))\n",
    "        for _ in range(max_iter):\n",
    "            clusters = [list() for i in range(k)]\n",
    "            # Update cluster assignments\n",
    "            for i in range(n):\n",
    "                vec = feat_vecs[i]\n",
    "                dist =  euclidean_distance(vec, centers, 1)\n",
    "                min_index = np.argmin(dist, axis=0)\n",
    "                clusters[min_index].append(i)\n",
    "            # Restart algorithm in case of empty clusters\n",
    "            if [] in clusters:\n",
    "                proceed = True\n",
    "                break\n",
    "            # Update centers\n",
    "            for i in range(k):\n",
    "                indices = clusters[i]\n",
    "                centers[i] = feat_vecs[indices].mean(axis=0)\n",
    "    return centers\n",
    "```\n",
    "[Benchmark of different k-means implementations in different libraries.](https://hdbscan.readthedocs.io/en/latest/performance_and_scalability.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
